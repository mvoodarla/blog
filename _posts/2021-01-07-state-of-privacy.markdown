---
layout: post
title:  "My Thoughts on Internet Echo Chambers"
date:   2021-01-07 00:00:00 -0700
categories: tech
---

With the recent news about the riots at [Capitol Hill][riots], it brought back to light the reasons behind why all this happened. This meme that Elon Musk tweeted is pretty characteristic of that.

![Domino Meme](https://pbs.twimg.com/media/ErGeSQTVoAMmwdb?format=jpg&name=large)

Over the last few days, I've been thinking about some of this a little more deeply but it's still hard to make sense of exactly what causes this sort of polarization. The two main ways that I know people get their news is from social media sites like Facebook and Twitter or from news outlets (TV or website or social media posts).

In terms of the news outlets, most people subconciously just listen to the ones that feed them information they want to hear. This results in them feeling that the truth is exactly what they hear without considering ulterior motives of the news anchors.

However, social media is by far the thing that contributes most to these echo chambers that result in all the riots and protests we see. As we know, platforms like Facebook track almost all of our internet usage and use it to not only feed us relevant ads but also target other content to which we'll have the most engagement. This is due to the fact that these companies want to increase our engagement with the app. However, most of the time this sort of engagement factor is where the most polarization exists, without real regard for right or wrong. It's also the space that results in people mindlessly believing in actual fake news and causing harm to the world because of it. Presidents like Donald Trump then supporting these people amplifies all said effects.

To break this down the effects of social media into steps, we have the following.

<ul>
<li>People use a platform because they want to interact with people on that platform</li>
<li>People see content they want to see and things they want to interact with</li>
<li>People create echo chambers based on their usage of a platform</li>
<li>People start believing in things that may not be true, unwilling to consider another possibility</li>
<li>Violence or hatred is incited</li>
</ul>

If we look at this list, things start going downhill at the point in which people only see things they want to see and not a reflection of the real world (but rather their ideal world). The main culprit here is the news feed algorithm. This algorithm constraints target content in such a way as to maximize Facebook ad revenue while the constraint should really abide to how the real world works. This maximization of ad revenue happens to be a thing because there is no other way Facebook tries to make money. So, in order for the news feed algorithm to change, we need to have a different way for a platform like this to survive and make money.

An obvious first option here could be to make it a subscription based service which has prices set by the goverment and partially funded through some taxpayer money. There are probably problems with this idea at face value but it does remove any ad and content targetting incentives.

Another option would be to have separate data stores and cloud data providers which have some sort of encryption on data being stored within the platform which can then be accessed by companies like Facebook as a third party. This ensures that there are multiple entities which keep each other in check as to how data is being used.

Another option would be to have trusted arbitors of truth (some sort of service) which then these platforms are forced to use to monitor and censor content that is blatantly false.

For a few other solutions, I probably have to think longer but overall, things are really screwed up right now and I don't think there are enough engineers focused on this problem.

[riots]: https://www.cnn.com/politics/live-news/washington-dc-election-riots/index.html